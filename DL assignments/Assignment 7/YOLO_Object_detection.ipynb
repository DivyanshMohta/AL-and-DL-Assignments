{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Function to perform object detection\n",
        "def detect_objects(image_path):\n",
        "    # Check if the image path exists\n",
        "    if not Path(image_path).exists():\n",
        "        print(f\"Image path {image_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image {image_path}.\")\n",
        "        return\n",
        "\n",
        "    # Convert the image from BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform inference\n",
        "    results = model(img_rgb)\n",
        "\n",
        "    # Check if any detections are made\n",
        "    if results.pred[0].shape[0] == 0:\n",
        "        print(\"No detections made.\")\n",
        "        return\n",
        "\n",
        "    # Parse the results\n",
        "    labels, confidences, boxes = results.xyxyn[0][:, -1].cpu().numpy(), results.xyxyn[0][:, -2].cpu().numpy(), results.xyxyn[0][:, :-2].cpu().numpy()\n",
        "\n",
        "    # Print the detections for debugging\n",
        "    print(\"Detections:\")\n",
        "    for label, confidence, box in zip(labels, confidences, boxes):\n",
        "        print(f\"Label: {model.names[int(label)]}, Confidence: {confidence}, Box: {box}\")\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img_rgb)\n",
        "    ax = plt.gca()\n",
        "    for box, label, confidence in zip(boxes, labels, confidences):\n",
        "      xmin, ymin, xmax, ymax = box\n",
        "      rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red', linewidth=2)\n",
        "      ax.add_patch(rect)\n",
        "      # Assuming you have access to class names from your model\n",
        "      class_name = model.names[int(label)]  # Replace with your method to get class names\n",
        "      text = f'{class_name} {confidence:.2f}'\n",
        "      ax.text(xmin, ymin, text, color='white', fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/dog_bike_car.jpg'\n",
        "\n",
        "# Detect objects in the image\n",
        "detect_objects(image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BivYHTD-t-94",
        "outputId": "9a1a316d-fde7-45c0-f98f-3e735f1bc40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-8-6 Python-3.10.12 torch-2.3.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detections:\n",
            "Label: dog, Confidence: 0.8928689360618591, Box: [    0.17412     0.37695     0.40216     0.94473]\n",
            "Label: car, Confidence: 0.7592323422431946, Box: [    0.61345     0.13077     0.89574     0.29992]\n",
            "Label: bicycle, Confidence: 0.4855104088783264, Box: [    0.19634      0.2051      0.7402     0.73971]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Function to perform object detection\n",
        "def detect_objects(image_path):\n",
        "    # Check if the image path exists\n",
        "    if not Path(image_path).exists():\n",
        "        print(f\"Image path {image_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image {image_path}.\")\n",
        "        return\n",
        "\n",
        "    # Convert the image from BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform inference\n",
        "    results = model(img_rgb)\n",
        "\n",
        "    # Check if any detections are made\n",
        "    if results.pred[0].shape[0] == 0:\n",
        "        print(\"No detections made.\")\n",
        "        return\n",
        "\n",
        "    # Parse the results\n",
        "    labels, confidences, boxes = results.xyxyn[0][:, -1].cpu().numpy(), results.xyxyn[0][:, -2].cpu().numpy(), results.xyxyn[0][:, :-2].cpu().numpy()\n",
        "\n",
        "    # Print the detections for debugging\n",
        "    print(\"Detections:\")\n",
        "    for label, confidence, box in zip(labels, confidences, boxes):\n",
        "        print(f\"Label: {model.names[int(label)]}, Confidence: {confidence}, Box: {box}\")\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img_rgb)\n",
        "    ax = plt.gca()\n",
        "    for box, label, confidence in zip(boxes, labels, confidences):\n",
        "      xmin, ymin, xmax, ymax = box\n",
        "      rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red', linewidth=2)\n",
        "      ax.add_patch(rect)\n",
        "      # Assuming you have access to class names from your model\n",
        "      class_name = model.names[int(label)]  # Replace with your method to get class names\n",
        "      text = f'{class_name} {confidence:.2f}'\n",
        "      ax.text(xmin, ymin, text, color='white', fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/UYYqo.jpg'\n",
        "\n",
        "# Detect objects in the image\n",
        "detect_objects(image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noGrAiIkwutg",
        "outputId": "b8f2b6c9-036f-4735-9da6-2a87e09ef25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-8-6 Python-3.10.12 torch-2.3.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detections:\n",
            "Label: apple, Confidence: 0.8677540421485901, Box: [    0.52389    0.086735     0.90491     0.44661]\n",
            "Label: banana, Confidence: 0.7494503855705261, Box: [    0.16729     0.53362     0.73024     0.89676]\n",
            "Label: orange, Confidence: 0.6917346119880676, Box: [   0.091484    0.090446     0.36795     0.37287]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Function to perform object detection\n",
        "def detect_objects(image_path):\n",
        "    # Check if the image path exists\n",
        "    if not Path(image_path).exists():\n",
        "        print(f\"Image path {image_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image {image_path}.\")\n",
        "        return\n",
        "\n",
        "    # Convert the image from BGR to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform inference\n",
        "    results = model(img_rgb)\n",
        "\n",
        "    # Check if any detections are made\n",
        "    if results.pred[0].shape[0] == 0:\n",
        "        print(\"No detections made.\")\n",
        "        return\n",
        "\n",
        "    # Parse the results\n",
        "    labels, confidences, boxes = results.xyxyn[0][:, -1].cpu().numpy(), results.xyxyn[0][:, -2].cpu().numpy(), results.xyxyn[0][:, :-2].cpu().numpy()\n",
        "\n",
        "    # Print the detections for debugging\n",
        "    print(\"Detections:\")\n",
        "    for label, confidence, box in zip(labels, confidences, boxes):\n",
        "        print(f\"Label: {model.names[int(label)]}, Confidence: {confidence}, Box: {box}\")\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img_rgb)\n",
        "    ax = plt.gca()\n",
        "    for box, label, confidence in zip(boxes, labels, confidences):\n",
        "      xmin, ymin, xmax, ymax = box\n",
        "      rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red', linewidth=2)\n",
        "      ax.add_patch(rect)\n",
        "      # Assuming you have access to class names from your model\n",
        "      class_name = model.names[int(label)]  # Replace with your method to get class names\n",
        "      text = f'{class_name} {confidence:.2f}'\n",
        "      ax.text(xmin, ymin, text, color='white', fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/media_16ad2258cac6171d66942b13b8cd4839f0b6be6f3.png'\n",
        "# Detect objects in the image\n",
        "detect_objects(image_path)\n"
      ],
      "metadata": {
        "id": "kusspAVz7yni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5739c91a-335d-4732-c8ec-7f0dae1b6f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-8-13 Python-3.10.12 torch-2.3.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detections:\n",
            "Label: dog, Confidence: 0.6985430121421814, Box: [    0.14248      0.1096     0.88528     0.97075]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwo3Ts6qqqGf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}